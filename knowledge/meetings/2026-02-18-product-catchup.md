# Product Catchup

**Date:** 2026-02-18

**Attendees:** 

## Summary

**Action Items:**
- **Rahul**: Access to Foundry Endpoints
- **Rahul**: LLM API Keys for AI Readiness Score

**Meeting Notes:**

### Demonstration of Coding Tools and Workflow
Jake provided Rahul with a walkthrough of using tools such as Koda, Claude code, and the process of creating a new React app, emphasizing the goal of leveraging these tools to automate and streamline development tasks.
  - **Tool Usage Overview**: Jake explained that the workflow involves using Koda and Claude code to automate coding tasks, including generating code and setting up projects, and demonstrated the creation of a new React app using these tools.
  - **SSH Key and Repo Cloning**: Jake showed how to obtain an SSH key from a Coda account, enabling users to clone repositories directly from the Coda terminal for streamlined development.
  - **Recommended Tools**: Jake recommended Rahul focus on using VS Code, Replit, and Claude code as the primary tools for development, suggesting these as the main resources to start with.
  - **Cost Considerations**: Jake advised Rahul to be mindful of costs associated with resources like Azure VMs, reminding them to delete unused instances to avoid unnecessary charges.

### Discussion on AI Readiness Score Implementation
Rahul asked Jake about the technical approach for implementing the AI readiness score task, specifically whether to use an LLM such as OpenAI or an agent AI from Microsoft Azure, and Jake clarified the intended workflow and available resources.
  - **LLM Integration for Scoring**: Rahul inquired if user responses for the AI readiness score should be processed by an LLM, and Jake confirmed that using an LLM is necessary for generating the score, with the plan to publish the assessment on LinkedIn for users to complete.
  - **API Key Provisioning**: Jake offered to provide API keys for the LLM if needed, ensuring Rahul would have the necessary access to integrate the model into the product.

### Clarification of Available AI Models and Endpoints
Rahul sought clarification on which AI models and endpoints are available for use, and Jake explained the team's access to Anthropic and OpenAI models via Microsoft Foundry, detailing the deployment process and rationale for using these resources.
  - **Available AI Models**: Jake stated that the team has access to Anthropic and OpenAI models but not Google, and demonstrated how to view and deploy available models through the Foundry platform.
  - **Deployment via Foundry**: Jake walked through the process of deploying a model such as GPT-5 using Foundry, explaining that an endpoint is generated for use in applications.
  - **Cost-Free Usage via Microsoft**: Jake clarified that the team uses Foundry endpoints because Microsoft provides funded subscriptions, making usage free for the team.
  - **Direct Use of Foundry Endpoints**: Rahul questioned why not use agent AI from Microsoft Azure directly, and Jake explained that the Foundry endpoints are the preferred method, as they provide access to the same models in a cost-effective manner.
  - **Access Confirmation**: Jake confirmed that Rahul should use the Foundry endpoints for all LLM-related tasks and asked Rahul to notify them if access issues arise; Rahul confirmed they have access.

### Support and Issue Resolution Process
Jake emphasized to Rahul the importance of quickly addressing any blockers or issues encountered during development, offering prompt support to ensure smooth progress.
  - **Blocker Removal Commitment**: Jake assured Rahul that any blockers should be communicated immediately so they can be resolved as quickly as possible to maintain development momentum.

## Transcript


