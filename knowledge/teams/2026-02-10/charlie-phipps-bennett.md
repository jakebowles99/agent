# Teams Chat â€” Charlie Phipps-Bennett

## 13:43 - Charlie Phipps-Bennett
> <attachment id="1770730928786"></attachment>
> oh god, best not to mention that lol

## 13:42 - Jake Bowles
> He wasn't that bothered but I also didn't tell him it was mainly for smaterd365 

## 13:41 - Jake Bowles
> The subscription has Â£2k of credit but claude models are excluded apparently

## 13:41 - Charlie Phipps-Bennett
> Oh my! Bet he was impressed!!
> 
> Silly <emoji id="rofl" alt="ðŸ¤£" title="Rolling on the floor laughing"></emoji>

## 13:40 - Jake Bowles
> Turns out it doesn't use azure credits so I spent Â£200 last month on api tokens lol

## 13:40 - Charlie Phipps-Bennett
> yes

## 13:40 - Jake Bowles
> So you know how i use claude code with our foundry?

## 13:39 - Charlie Phipps-Bennett
> No what happened?

## 13:38 - Jake Bowles
> Did Andy tell you about my Azure mishap?

## 17:10 - Jake Bowles
> How did it go?


# Teams Chat â€” Charlie Phipps-Bennett

## 14:00 - Jake Bowles
> i do now

## 13:53 - Charlie Phipps-Bennett
> got 5mins?

# Teams Chat â€” Charlie Phipps-Bennett

## 14:06 - Jake Bowles
> <p>When do they want a response?&nbsp;</p>

## 14:01 - Charlie Phipps-Bennett
> <ol>
<li style="margin-bottom:0px; margin-top:0px"><span style="font-size:inherit"><strong>Handwritten notes: </strong>I saw a demo a few weeks back where handwritten notes were being extracted which needed to be validated and checked for accuracy. Is this still part of the build, and if it is how can the user see this was an extraction from a hand-written medical file and likely needs additional review?</span></li><li style="margin-bottom:0px; margin-top:0px"><span style="font-size:inherit"><strong>Handling Duplicated Records:</strong> please confirm there will be no duplicated records extracted, whether it is the 1st, 2nd or 3rd extractions</span></li><li style="margin-bottom:0px; margin-top:0px"><span style="font-size:inherit"><strong>AI Extraction Module</strong>: Extracts key clinical and administrative data using pre-trained models and rule-based tagging. How it is learning what evidence is it pulling is good evidence and user-worthy, and how is it self-learning, or using the Approve/reject tool as learning? Do we need to give you real-life example DST medical extraction cases extracted and upload into the tool for the learning to be more accurate or does this happen as we use it more and more?</span></li></ol>
<p style="margin-bottom:0px; margin-top:0px"><span style="font-size:inherit">Compass have asked the above ^</span></p>

## 14:00 - Jake Bowles
> <p>i do now</p>

## 13:53 - Charlie Phipps-Bennett
> <p>got 5mins?</p>

## 13:43 - Charlie Phipps-Bennett
> <attachment id="1770730928786"></attachment>
<p>oh god, best not to mention that lol</p>

## 13:42 - Jake Bowles
> <p>He wasn't that bothered but I also didn't tell him it was mainly for smaterd365 </p>

## 13:41 - Jake Bowles
> <p>The subscription has 000 of credit but claude models are excluded apparently</p>

## 13:41 - Charlie Phipps-Bennett
> <p>Oh my! Bet he was impressed!!</p>
<p>&nbsp;</p>
<p>Silly&nbsp;<emoji id="rofl" alt="e" title="Rolling on the floor laughing"></emoji></p>

## 13:40 - Jake Bowles
> <p>Turns out it doesn't use azure credits so I spent 000 last month on api tokens lol</p>

## 13:40 - Charlie Phipps-Bennett
> <p>yes</p>


## 14:36 - Charlie Phipps-Bennett
> <p>Can I ask Tim, would he know?</p>

## 14:36 - Jake Bowles
> <p>Will be on DND&nbsp;</p>

## 14:36 - Jake Bowles
> <p>I really need to get Jensten done after this&nbsp;</p>

## 14:32 - Charlie Phipps-Bennett
> <p>Could we talk about it in 5mins after this and I deal with the response or will it take longer?</p>

## 14:31 - Jake Bowles
> <p>I am absolutely fucked today&nbsp;</p>

## 14:31 - Jake Bowles
> <p>No chance sorry</p>

## 14:20 - Charlie Phipps-Bennett
> <p>COP <emoji id="smile" alt="ðŸ™‚" title="Smile"></emoji></p>

## 14:06 - Jake Bowles
> <p>When do they want a response?&nbsp;</p>

## 14:01 - Charlie Phipps-Bennett
> <ol>
<li style="margin-bottom:0px; margin-top:0px"><span style="font-size:inherit"><strong>Handwritten notes: </strong>I saw a demo a few weeks back where handwritten notes were being extracted which needed to be validated and checked for accuracy. Is this still part of the build, and if it is how can the user see this was an extraction from a hand-written medical file and likely needs additional review?</span></li><li style="margin-bottom:0px; margin-top:0px"><span style="font-size:inherit"><strong>Handling Duplicated Records:</strong> please confirm there will be no duplicated records extracted, whether it is the 1st, 2nd or 3rd extractions</span></li><li style="margin-bottom:0px; margin-top:0px"><span style="font-size:inherit"><strong>AI Extraction Module</strong>: Extracts key clinical and administrative data using pre-trained models and rule-based tagging. How it is learning what evidence is it pulling is good evidence and user-worthy, and how is it self-learning, or using the Approve/reject tool as learning? Do we need to give you real-life example DST medical extraction cases extracted and upload into the tool for the learning to be more accurate or does this happen as we use it more and more?</span></li></ol>
<p style="margin-bottom:0px; margin-top:0px"><span style="font-size:inherit">Compass have asked the above ^</span></p>

## 14:00 - Jake Bowles
> <p>i do now</p>


## 15:10 - Jake Bowles
> <ol>
<li>Possible with little additional work from what I can tell</li><li>Can't confirm this, would like to think not?</li><li>It is not self learning but it can be trained but requires a shit load of effort from their side</li></ol>

# Teams Chat â€” Charlie Phipps-Bennett

## 16:15 - Jake Bowles
> nah pre-trained means off the shelf

## 16:10 - Charlie Phipps-Bennett
> pre-trained

## 16:10 - Charlie Phipps-Bennett
> Does this req put us in the shit?

## 16:10 - Charlie Phipps-Bennett
> AI Extraction Module: Extracts key clinical and administrative data using pre-trained models and rule-based tagging (FR-011, USTR-017).



## 16:24 - Jake Bowles
> <p>Add a note that in our experience context engineering can help to a good level&nbsp;</p>

## 16:21 - Charlie Phipps-Bennett
> <p>Think I am going to say this</p>

## 16:21 - Charlie Phipps-Bennett
> <p><strong>AI Extraction Module  Learning &amp; Training</strong><br>
> Per the SoW, the module uses:<br>
> <i>pretrained models and rulebased tagging (FR011, USTR017)</i></p>
> <p>We are using Azure AI Foundrys Content Understanding model.<br>
> Important notes:</p>
> <ul>
> <li><span style="font-size:inherit">It is not selflearning.</span></li>
> <li><span style="font-size:inherit">It canbe trained but only through a structured training process requiring a lot of effort from your side.</span></li>
> <li><span style="font-size:inherit">If you wish to improve accuracy further, we can work with you to train it using real DST cases, but this effort would sit outside the current scope.</span></li>
> </ul>

## 16:15 - Charlie Phipps-Bennett
> <p>Perfect, glad I worded it like that</p>

## 16:15 - Jake Bowles
> <p>nah pre-trained means off the shelf</p>

## 16:10 - Charlie Phipps-Bennett
> <p>pre-trained</p>

## 16:10 - Charlie Phipps-Bennett
> <p>Does this req put us in the shit?</p>

## 16:10 - Charlie Phipps-Bennett
> <p>AI Extraction Module: Extracts key clinical and administrative data using pre-trained models and rule-based tagging (FR-011, USTR-017).</p>

# Teams Chat â€” Charlie Phipps-Bennett

## 23:01 - Jake Bowles
> What fires are you fighting atm?


## 23:01 - Jake Bowles
> What fires are you fighting atm?

## 23:21 - Charlie Phipps-Bennett
> Compass CMS but its out the door
